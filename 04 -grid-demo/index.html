<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>High Park News</title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <link rel="stylesheet" href="style.css">
    </head>
    <body>

        <div class="grid-container">

            <div class="header">

                <h1>High Park News</h1>

            </div>

            <div class="sidebar">
                <div class="news-item">
                    <img src="https://nas-national-prod.s3.amazonaws.com/styles/hero_cover_bird_page/s3/web_a1_5046_4_barred-owl_tom_ingram-adults.jpg?itok=VozFm0tx">
                    <h3>Owl Spotted near Grenadier Pong</h3>
                    <p>On February 5th, a Barred Owl was seen by the water.</p>
                </div>


                <div class="news-item">
                    
                    <h3>Social distance? But what about the cherry blossoms?!</h3>
                    <p>Mayor closes park drives design professor to unrelenting anger.</p>
                </div>

                
            </div>
            
            <div class="main">
                
            <p>
                Just as the keyboard is waiting for a key to be pressed, the computer is waiting for a signal from the keyboard. When one comes down the pike, the computer interprets it and passes it farther into its own interior. “Here’s what the keyboard just received—do with this what you will.”
            </p>
            <p>
                It’s simple now, right? The computer just goes to some table, figures out that the signal corresponds to the letter “a,” and puts it on screen. Of course not—too easy. Computers are machines. They don’t know what a screen or an “a” are. To put the “a” on the screen, your computer has to pull the image of the “a” out of its memory as part of a font, an “a” made up of lines and circles. It has to take these lines and circles and render them in a little box of pixels in the part of its memory that manages the screen. So far we have at least three representations of one letter: the signal from the keyboard; the version in memory; and the lines-and-circles version sketched on the screen. We haven’t even considered how to store it, or what happens to the letters to the left and the right when you insert an “a” in the middle of a sentence. Or what “lines and circles” mean when reduced to binary data. There are surprisingly many ways to represent a simple “a.” It’s amazing any of it works at all.
            </p>
            <p>    
                Coders are people who are willing to work backward to that key press. It takes a certain temperament to page through standards documents, manuals, and documentation and read things like “data fields are transmitted least significant bit first” in the interest of understanding why, when you expected “ü,” you keep getting “�.”
            </p>
            <p>    
                2.2From Hardware to Software
                Hardware is a tricky business. For decades the work of integrating, building, and shipping computers was a way to build fortunes. But margins tightened. Look at Dell, now back in private hands, or Gateway, acquired by Acer. Dell and Gateway, two world-beating companies, stayed out of software, typically building PCs that came preinstalled with Microsoft Windows—plus various subscription-based services to increase profits.
            </p>
            <p>    
                This led to much cursing from individuals who’d spent $1,000 or more on a computer and now had to figure out how to stop the antivirus software from nagging them to pay up.
            </p>
            <p>   
                Steve Ballmer
                Ballmer chants “Developers!”
                SOURCE: YOUTUBE
                Years ago, when Microsoft was king, Steve Ballmer, sweating through his blue button-down, jumped up and down in front of a stadium full of people and chanted, “Developers! Developers! Developers! Developers!”
            </p>
            <p>   
                He yelled until he was hoarse: “I love this company!” Of course he did. If you can sell the software, if you can light up the screen, you’re selling infinitely reproducible nothings. The margins on nothing are great—until other people start selling even cheaper nothings or giving them away. Which is what happened, as free software-based systems such as Linux began to nibble, then devour, the server market, and free-to-use Web-based applications such as Google Apps began to serve as viable replacements for desktop software.
            </p>
            <p>   
                Expectations around software have changed over time. IBM unbundled software from hardware in the 1960s and got to charge more; Microsoft rebundled Internet Explorer with Windows in 1998 and got sued; Apple initially refused anyone else the ability to write software for the iPhone when it came out in 2007, and then opened the App Store, which expanded into a vast commercial territory—and soon the world had Angry Birds. Today, much hardware comes with some software—a PC comes with an operating system, for example, and that OS includes hundreds of subprograms, from mail apps to solitaire. Then you download or buy more.
            </p>
            <p>  
            </p>
            <p>   There have been countless attempts to make software easier to write, promising that you could code in plain English, or manipulate a set of icons, or make a list of rules—software development so simple that a bright senior executive or an average child could do it. Decades of efforts have gone into helping civilians write code as they might use a calculator or write an e-mail. Nothing yet has done away with developers, developers, developers, developers.
                
                Thus a craft, and a professional class that lives that craft, emerged. Beginning in the 1950s, but catching fire in the 1980s, a proportionally small number of people became adept at inventing ways to satisfy basic human desires (know the time, schedule a flight, send a letter, kill a zombie) by controlling the machine. Coders, starting with concepts such as “signals from a keyboard” and “numbers in memory,” created infinitely reproducible units of digital execution that we call software, hoping to meet the needs of the marketplace. Man, did they. The systems they built are used to manage the global economic infrastructure.1 If coders don’t run the world, they run the things that run the world.

            </p>
            </div>


            <div class="sidebar">
                <div class="news-item">
                    <img src="https://i2-prod.dailyrecord.co.uk/incoming/article10774626.ece/ALTERNATES/s615/GettyImages-730274683.jpg">
                    <h3>Highland Cow Gets Horn Stuck in Door</h3>
                    <p></p>
                </div>
            </div>
        
            <div class="footer">
                designed by Ali.
            </div>
        </div>

    </body>
</html>